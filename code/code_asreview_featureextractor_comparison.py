# -*- coding: utf-8 -*-
"""Code_ASReview_FeatureExtractor_Comparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1owOyxCUdRkP8MWBwGXgzW_WhNi96-1eU

# ASReview - Testing Different Feature Extraction Methods

The goal is to compare classical feature extraction methods to transformer (state-of-the-art) feature extraction models, in the context of systematic reviews. To study the effect of transformer feature extractors, three new feature extraction models are implemented using the ASReview software. The new feature extraction models used for the simulations are:

1. **RoBERTa-base** (stsb-roberta-base-v2) → *transformer/state-of-the-art (SOTA) model*
2. **DistilRoBERTa** (all-distilroberta-v1) → *transformer/state-of-the-art (SOTA) model*
3. **SPECTER** (allenai-specter) → *transformer/state-of-the-art (SOTA) model*

The new models are comapred with three feature extraction models previously implemented by ASReview: 
4. **MPNET** (all-mpnet-base-v2), ASReview default transformer model → *transformer/state-of-the-art (SOTA) model*
5. **Tf-idf** → *classical model*
6. **Doc2Vec** → *classical model*

The transformer feature extractors are implemented using the sentence transformer from the [Hugging Face](https://huggingface.co/sentence-transformers) library.

The Python API documentation for ASReview (used for the simulations below) can be found at: https://asreview.readthedocs.io/en/latest/reference.html (but please note that version 0.19.3 was used for this study; the newer version of ASReview is 1.0). Full ASReview code can be found on: https://github.com/asreview/asreview
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # to record runtime
# !pip install ipython-autotime
# %load_ext autotime

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # install ASReview software
# !pip install asreview=="0.19.3"

# import libraries
import numpy as np
import pandas as pd

# import libraries from asreview
import asreview
from asreview.models import *
from asreview.query_strategies import *
from asreview.balance_strategies import *
from asreview.feature_extraction import *

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # install statistics (contains metrics) and visualization libraries from asreview
# !pip install asreview-statistics asreview-visualization

# to check if I'm using a high-ram runtime
from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

"""## Import Data:

The PTSD Trajectories benchmark dataset by Van de Schoot et al. was chosen. This dataset deals with PTSD trajectories and uses articles about longitudinal studies examining posttraumatic stress after trauma (van de Schoot et al., 2017; van de Schoot et al., 2018). The dataset contains 6,189 studies that were extracted from Pubmed, Embase, PsychInfo, and Scopus, and as this is a labeled dataset, it is known that 43 of those studies are considered “relevant” (included in the systematic review).

- Note: All of the benchmark datasets can be found on Github: https://github.com/asreview/systematic-review-datasets
"""

# import van_de_Schoot dataset (Method 1 - Github link)
url = "https://raw.githubusercontent.com/asreview/systematic-review-datasets/master/datasets/van_de_Schoot_2017/output/van_de_Schoot_2017.csv"
data = pd.read_csv(url)

# import van_de_Schoot dataset (Method 2 - Import local file)
#data = pd.read_csv("/content/van_de_Schoot_2017.csv")

# view data
data.head()

# have to ensure the columns are string type for the simulations to be run
data['abstract'] = data['abstract'].astype(str)
data['keywords'] = data['keywords'].astype(str)
data['title'] = data['title'].astype(str)
data['authors'] = data['authors'].astype(str)

"""## Hugging Face *sentence transformers* library:

All sentence transformer models in this study were implemented using the [sentence-transformers library](https://huggingface.co/sentence-transformers) on Hugging Face. Hugging face (https://huggingface.co/) is a website containing open-source machine learning models and allows users to upload and download models for free, including a wide variety of sentence transformer models.

A few things to note about Hugging Face model selection:
- Model version and the number of downloads were both examined when selecting which model to implement from the sentence-transformers page 
- The “base” (stsb-roberta-base-v2) version of the RoBERTa model was selected 
- The “distil” (all-distilroberta-v1) version of the RoBERTa model was also  selected. The “distilled” version is a lighter and faster version of the "base" model with half the number of layers and a little over half of the parameters
- MPNET and SPECTER were also implemented using the sentence transformers library
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install -U sentence-transformers

from sentence_transformers import SentenceTransformer

"""#### Side-note: Code for working with the Sentence Transformers library
- if needed, one can extract the features matrix using the sentence transformers library 
"""

# Ex of how to use this library to extract embeddings

'''
sentences = ["This is an example sentence", "Each sentence is converted"]

model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
embeddings = model.encode(sentences)
print(embeddings)
'''

"""Below is an example of how features can be extracted using the dataset of this study: """

# run SBERT model on abstracts from van de Schoot dataset
abstracts = data[['abstract']]

# turn asbtracts into list
abstracts = abstracts.astype(str)
abstracts_list = abstracts.values.tolist()

data['abstract'] = data['abstract'].astype(str)
corpus = data.abstract.tolist()

type(corpus) # is a list now
len(corpus)

# Run Hugging Face model and extract features
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
embeddings_schoot = model.encode(corpus)
print(embeddings_schoot)

"""## Simulation Mode: from ASReview Documentation
- The ASReview code for all feature extraction models can be found on Github: https://github.com/asreview/asreview/tree/master/asreview/models/feature_extraction
"""

# set seed
import random
random.seed(10)

"""## **Running the Simulations:**

Most of the simulations were run in a loop that uses the Python API to produce the state file and then the command line to calculate the metrics using the [ASReview *statistics* library](https://pypi.org/project/asreview-statistics/). For convenience, all simulations using the NN2 classifier were run separately due to the fact that it takes a long time to run. The NN2 classifier could easily be added to the simulation loop with the other classifiers if preferred.
- Note: initial_seed has been set in the simulation settings to reduce randomness and decrease bias when comparing models. However, each time the simulation is run the model will be slightly different, especially for feature extractors like the transformer models since they are not deterministic models.
- For further explanations about the metrics used, please refer to: https://asreview.nl/blog/simulation-mode-class-101/
- The following default settings have been used for the simulations: 
  - Query strategy: max query
  - Balance strategy: double balance
  - Number of instances: 10
  - Initial seed: 10 (can be any fixed number)
  - Prior knowledge: 1 relevant, 1 irrelevant

# (1) Feature Extractor: RoBERTa-base

The model is: "stsb-roberta-base-v2"

https://huggingface.co/sentence-transformers/stsb-roberta-base-v2

Running the RoBERTa-base model with the SVM, Logistic Regression, Random Forest, and NN2 classifiers:
"""



# list of state file names
state_file_list = ["schoot_robertabase_SVM.h5", "schoot_robertabase_LR.h5","schoot_robertabase_RF.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier()]

# RoBERTa-base - run on all classifiers but NN2
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "stsb-roberta-base-v2")

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data,
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# metrics for robertba-base feature extractor (for all classifiers) 
!asreview stat "/content/schoot_robertabase_SVM.h5"
!asreview stat "/content/schoot_robertabase_LR.h5"
!asreview stat "/content/schoot_robertabase_RF.h5"

# RoBERTa-base - run on NN2
import random 
random.seed(10)

# Load data
as_data = asreview.data.ASReviewData(df = data)
# Settings
train_model = NN2LayerClassifier()
query_model = MaxQuery()
balance_model = DoubleBalance()
feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "stsb-roberta-base-v2")

# Start the review process
reviewer_full_schoot = asreview.ReviewSimulate(
    as_data,
    model=train_model,
    query_model=query_model,
    balance_model=balance_model,
    feature_model=feature_model,
    n_instances=10,
    init_seed=10,
    n_prior_included=1,
    n_prior_excluded=1,
    state_file="/content/schoot_robertabase_NN2.h5"
)
reviewer_full_schoot.review()

# metrics for robertba-base feature extractor with NN2
!asreview stat "/content/schoot_robertabase_NN2.h5"

"""# (2) Feature Extractor: All-distilroberta-v1
- The documentation for this model can be found on Hugging Face: https://huggingface.co/sentence-transformers/all-distilroberta-v1

Running the DistilRoBERTa model with the SVM, Logistic Regression, Random Forest, and NN2 classifiers:
"""

# list of state file names
state_file_list = ["schoot_distilroberta_SVM.h5", "schoot_distilroberta_LR.h5","schoot_distilroberta_RF.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier()]

# All-distilroberta-v1 - run on all classifiers but NN2
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "all-distilroberta-v1")

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data,
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# metrics for distilroberta feature extractor (for all classifiers but NN2) 
!asreview stat "/content/schoot_distilroberta_SVM.h5"
!asreview stat "/content/schoot_distilroberta_LR.h5"
!asreview stat "/content/schoot_distilroberta_RF.h5"

# All-distilroberta-v1 - run with NN2
import random 
random.seed(10)

# Load data
as_data = asreview.data.ASReviewData(df = data)
# Settings
train_model = NN2LayerClassifier()
query_model = MaxQuery()
balance_model = DoubleBalance()
feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "all-distilroberta-v1")

# Start the review process
reviewer_full_schoot = asreview.ReviewSimulate(
    as_data,
    model=train_model,
    query_model=query_model,
    balance_model=balance_model,
    feature_model=feature_model,
    n_instances=10,
    init_seed=10,
    n_prior_included=1,
    n_prior_excluded=1,
    state_file="/content/schoot_distilroberta_NN2.h5"
)
reviewer_full_schoot.review()

# metrics for distilroberta feature extractor with NN2 
!asreview stat "/content/schoot_distilroberta_NN2.h5"

"""# (3) Feature Extractor: Tf-idf

Implementation of Tf-idf from ASReview (uses the sklearn library): https://github.com/asreview/asreview/blob/master/asreview/models/feature_extraction/tfidf.py

Running the tf-idf model with the SVM, Logistic Regression, Random Forest, NN2, and Naive Bayes classifiers: 

- Note: Tf-idf is the only feature extractor that Naive Bayes can be run with
"""

# list of state file names
state_file_list = ["schoot_tfidf_SVM.h5", "schoot_tfidf_LR.h5","schoot_tfidf_RF.h5", "schoot_tfidf_NB.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier(), NaiveBayesClassifier()]

# TF-IDF - run on all classifiers but NN2 (including Naive Bayes)
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = Tfidf()

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data, 
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# TF-IDF - run on NN2
import random 
random.seed(10)

# Load data
as_data = asreview.data.ASReviewData(df = data)
# Settings
train_model = NN2LayerClassifier()
query_model = MaxQuery()
balance_model = DoubleBalance()
feature_model = Tfidf()

# Start the review process
reviewer_full_schoot = asreview.ReviewSimulate(
    as_data, 
    model=train_model,
    query_model=query_model,
    balance_model=balance_model,
    feature_model=feature_model,
    n_instances=10,
    init_seed=10,
    n_prior_included=1,
    n_prior_excluded=1,
    state_file="schoot_tfidf_NN2.h5"
)
reviewer_full_schoot.review()

# metrics for tf-idf feature extractor (for all classifiers but NN2) 
!asreview stat "/content/schoot_tfidf_SVM.h5"
!asreview stat "/content/schoot_tfidf_LR.h5"
!asreview stat "/content/schoot_tfidf_RF.h5"
!asreview stat "/content/schoot_tfidf_NB.h5"

# metrics for tf-idf with NN2
!asreview stat "/content/schoot_tfidf_NN2.h5"

"""# (4) Feature Extractor: Doc2Vec
The ASReview implementation of Doc2Vec (uses the gensim library): https://github.com/asreview/asreview/blob/master/asreview/models/feature_extraction/doc2vec.py

Running the Doc2Vec model with the SVM, Logistic Regression, Random Forest, and NN2 classifiers: 
- Note: Doc2Vec is the sentence-embedding level version of Word2Vec
"""

# list of state file names
state_file_list = ["schoot_doc2vec_SVM.h5", "schoot_doc2vec_LR.h5","schoot_doc2vec_RF.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier()]

# Doc2Vec - run on all classifiers (except NN2)
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = Doc2Vec()

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data, 
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# metrics for doc2vec feature extractor (for all but NN2 classifiers) 
!asreview stat "/content/schoot_doc2vec_SVM.h5"
!asreview stat "/content/schoot_doc2vec_LR.h5"
!asreview stat "/content/schoot_doc2vec_RF.h5"

# Doc2Vec - run on NN2 classifier
import random 
random.seed(10)  

# Load data
as_data = asreview.data.ASReviewData(df = data)
# Settings
train_model = NN2LayerClassifier()
query_model = MaxQuery()
balance_model = DoubleBalance()
feature_model = Doc2Vec()

# Start the review process
reviewer_full_schoot = asreview.ReviewSimulate(
    as_data, 
    model=train_model,
    query_model=query_model,
    balance_model=balance_model,
    feature_model=feature_model,
    n_instances=10,
    init_seed=10,
    n_prior_included=1,
    n_prior_excluded=1,
    state_file="schoot_doc2vec_NN2.h5"
)
reviewer_full_schoot.review()

# metrics for NN2 classifier
!asreview stat "/content/schoot_doc2vec_NN2.h5"

"""# (5) Feature Extractor: Allenai-specter

- Scientific texts were part of the corpus it was trained on 
- The research paper for the SPECTER model: https://arxiv.org/abs/2004.07180
- Implemented using the Hugging Face sentence transformers library --> full model name on Hugging Face is "sentence-transformers/allenai-specter" : https://huggingface.co/sentence-transformers/allenai-specter

Running the allenai-specter model with the SVM, Logistic Regression, Random Forest, and NN2 classifiers:
"""

# list of state file names
state_file_list = ["schoot_specter_SVM.h5", "schoot_specter_LR.h5","schoot_specter_RF.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier()]

# Allenai-specter - run on all classifiers
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "sentence-transformers/allenai-specter")

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data, 
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# metrics for SPECTER feature extractor (for all classifiers but NN2) 
!asreview stat "/content/schoot_specter_SVM.h5"
!asreview stat "/content/schoot_specter_LR.h5"
!asreview stat "/content/schoot_specter_RF.h5"

# Allenai-specter - run on NN2
import random 
random.seed(10)

# Load data
as_data = asreview.data.ASReviewData(df = data)
# Settings
train_model = NN2LayerClassifier()
query_model = MaxQuery()
balance_model = DoubleBalance()
feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "sentence-transformers/allenai-specter")

# Start the review process
reviewer_full_schoot = asreview.ReviewSimulate(
    as_data, 
    model=train_model,
    query_model=query_model,
    balance_model=balance_model,
    feature_model=feature_model,
    n_instances=10,
    init_seed=10,
    n_prior_included=1,
    n_prior_excluded=1,
    state_file="/content/schoot_specter_NN2.h5"
)
reviewer_full_schoot.review()

# metrics for SPECTER feature extractor with NN2
!asreview stat "/content/schoot_specter_NN2.h5"

"""# (6) Feature Extractor: All-mpnet-base-v2 (ASReview default model) 
- The default SBERT-based model that ASReview currently uses: https://github.com/asreview/asreview/blob/master/asreview/models/feature_extraction/sbert.py
- Also implemented using the sentence transformers library on Hugging Face: https://huggingface.co/sentence-transformers/all-mpnet-base-v2

Running the all-mpnet-base-v2 model with the SVM, Logistic Regression, Random Forest, and NN2 classifiers:
"""

# list of state file names
state_file_list = ["schoot_mpnet_SVM.h5", "schoot_mpnet_LR.h5","schoot_mpnet_RF.h5", "schoot_mpnet_NN2.h5"]
# list of classifiers
classifier_list = [SVMClassifier(), LogisticClassifier(), RandomForestClassifier(), NN2LayerClassifier()]

# MPNET - run on all classifiers
import random 
random.seed(10)

for i in range(0, len(state_file_list)):
  # Load data
  as_data = asreview.data.ASReviewData(df = data)
  # Settings
  train_model = classifier_list[i]
  query_model = MaxQuery()
  balance_model = DoubleBalance()
  feature_model = asreview.models.feature_extraction.SBERT(transformer_model= "sentence-transformers/all-mpnet-base-v2")

  # Start the review process
  reviewer_full_schoot = asreview.ReviewSimulate(
      as_data, 
      model=train_model,
      query_model=query_model,
      balance_model=balance_model,
      feature_model=feature_model,
      n_instances=10,
      init_seed=10,
      n_prior_included=1,
      n_prior_excluded=1,
      state_file=state_file_list[i]
  )
  reviewer_full_schoot.review()

# metrics for MPNET feature extractor (for all classifiers) 
!asreview stat "/content/schoot_mpnet_SVM.h5"
!asreview stat "/content/schoot_mpnet_LR.h5"
!asreview stat "/content/schoot_mpnet_RF.h5"
!asreview stat "/content/schoot_mpnet_NN2.h5"



